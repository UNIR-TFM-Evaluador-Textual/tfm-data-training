{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNYOppxTGphyHF8yWaQm+3n"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b636b1b2d44d4c19acf15e81e4bb845a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82b3c5be8c80469c8c10f3e7d012aeec","IPY_MODEL_df351c17dae94ba89d0b0b58629a6bfa","IPY_MODEL_fd36a96cb01f4f0aa377af03c6ffed7b"],"layout":"IPY_MODEL_ef5424cbc14040e8aca98abf56ce7f05","tabbable":null,"tooltip":null}},"82b3c5be8c80469c8c10f3e7d012aeec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_a87a66a2e9a6469fa69d8b0e524944bb","placeholder":"​","style":"IPY_MODEL_50dce87064b74b9cbbb0e3738b5af021","tabbable":null,"tooltip":null,"value":"Map: 100%"}},"df351c17dae94ba89d0b0b58629a6bfa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_cc7a41af1370480bab9f583470aa33c8","max":6000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea79fe403d7c47e386b52c22cf6b787d","tabbable":null,"tooltip":null,"value":6000}},"fd36a96cb01f4f0aa377af03c6ffed7b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"2.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_93a8a64031c54fe983c69b3baad313e9","placeholder":"​","style":"IPY_MODEL_2c2780335e54467fad18076a79897e40","tabbable":null,"tooltip":null,"value":" 6000/6000 [00:03&lt;00:00, 1978.49 examples/s]"}},"ef5424cbc14040e8aca98abf56ce7f05":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a87a66a2e9a6469fa69d8b0e524944bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50dce87064b74b9cbbb0e3738b5af021":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cc7a41af1370480bab9f583470aa33c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea79fe403d7c47e386b52c22cf6b787d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93a8a64031c54fe983c69b3baad313e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c2780335e54467fad18076a79897e40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLStyleModel","model_module_version":"2.0.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}}}}},"cells":[{"cell_type":"markdown","source":["\n","\n","# ==>   **MODELO MULTICLASE**\n","\n"],"metadata":{"id":"JFe0jtlS4HRx"}},{"cell_type":"markdown","source":["1. Modelo personalizado: RobertaMultitaskClassifier"],"metadata":{"id":"bjegvpPz4bFb"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from datasets import Dataset\n","from transformers import (\n","    AutoTokenizer,\n","    TrainingArguments,\n","    Trainer,\n","    AutoModel\n",")\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score"],"metadata":{"id":"u5shQoBjiBpp","executionInfo":{"status":"ok","timestamp":1751248282038,"user_tz":300,"elapsed":10,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ========== PARTE 2: Modelo multitarea ==========\n","class RobertaMultitaskClassifier(nn.Module):\n","    def __init__(self, model_name, num_labels_age=3, num_labels_gender=2, dropout=0.3):\n","        super().__init__()\n","        self.encoder = AutoModel.from_pretrained(\n","            model_name,\n","            trust_remote_code=True,\n","            use_safetensors=True\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","        hidden_size = self.encoder.config.hidden_size\n","        self.classifier_age = nn.Linear(hidden_size, num_labels_age)\n","        self.classifier_gender = nn.Linear(hidden_size, num_labels_gender)\n","\n","    def forward(self, input_ids, attention_mask, labels_age=None, labels_gender=None):\n","        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n","        pooled = outputs.last_hidden_state[:, 0, :]\n","        pooled = self.dropout(pooled)\n","        logits_age = self.classifier_age(pooled)\n","        logits_gender = self.classifier_gender(pooled)\n","\n","        loss = None\n","        if labels_age is not None and labels_gender is not None:\n","            loss_age = nn.CrossEntropyLoss()(logits_age, labels_age)\n","            loss_gender = nn.CrossEntropyLoss()(logits_gender, labels_gender)\n","            loss = loss_age + loss_gender\n","\n","        return {\"loss\": loss, \"logits_age\": logits_age, \"logits_gender\": logits_gender}"],"metadata":{"id":"Ppirk-yDEYAr","executionInfo":{"status":"ok","timestamp":1751248232560,"user_tz":300,"elapsed":4243,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ========== PARTE 1: Preparar dataset ==========\n","\n","# Cargar CSV\n","# Asegúrate de que el CSV tenga: text_es, age_group, gender\n","df = pd.read_csv(\"publico_blog_authorship_translated.csv\")\n","\n","# Mapear labels\n","df = df[df['age_group'].isin(['18-29', '30-39', '40-49'])]\n","df = df[df['gender'].isin(['male', 'female'])]\n","df['label_age'] = df['age_group'].map({'18-29': 0, '30-39': 1, '40-49': 2})\n","df['label_gender'] = df['gender'].map({'male': 0, 'female': 1})\n","\n","# Crear dataset de Hugging Face\n","dataset = Dataset.from_pandas(df)\n","tokenizer = AutoTokenizer.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\")\n","\n","def tokenize(example):\n","    tokens = tokenizer(example['text_es'], padding='max_length', truncation=True, max_length=128)\n","    tokens['labels_age'] = example['label_age']\n","    tokens['labels_gender'] = example['label_gender']\n","    return tokens\n","\n","dataset = dataset.map(tokenize)\n","dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels_age', 'labels_gender'])\n","\n","split = dataset.train_test_split(test_size=0.2, seed=42)\n","train_dataset = split['train']\n","test_dataset = split['test']\n","\n","\n","# ========== PARTE 3: Métricas ==========\n","def compute_metrics_multitask(eval_pred):\n","    logits_age, logits_gender = eval_pred.predictions\n","    labels_age, labels_gender = eval_pred.label_ids\n","    preds_age = np.argmax(logits_age, axis=1)\n","    preds_gender = np.argmax(logits_gender, axis=1)\n","\n","    return {\n","        \"accuracy_age\": accuracy_score(labels_age, preds_age),\n","        \"f1_age\": f1_score(labels_age, preds_age, average=\"macro\"),\n","        \"accuracy_gender\": accuracy_score(labels_gender, preds_gender),\n","        \"f1_gender\": f1_score(labels_gender, preds_gender, average=\"macro\")\n","    }\n","\n","# ========== PARTE 4: Trainer personalizado ==========\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n","        labels_age = inputs.pop(\"labels_age\")\n","        labels_gender = inputs.pop(\"labels_gender\")\n","        outputs = model(**inputs, labels_age=labels_age, labels_gender=labels_gender)\n","        loss = outputs[\"loss\"]\n","        return (loss, outputs) if return_outputs else loss\n","\n","# ========== PARTE 5: Entrenamiento ==========\n","model = RobertaMultitaskClassifier(\"PlanTL-GOB-ES/roberta-base-bne\")\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./modelo_publico\",\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    num_train_epochs=6,\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    weight_decay=0.01,\n","    logging_dir=\"./logs\",\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1_age\",\n","    greater_is_better=True\n",")\n","\n","trainer = CustomTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n","    compute_metrics=compute_metrics_multitask\n",")\n","\n","trainer.train()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":596,"referenced_widgets":["b636b1b2d44d4c19acf15e81e4bb845a","82b3c5be8c80469c8c10f3e7d012aeec","df351c17dae94ba89d0b0b58629a6bfa","fd36a96cb01f4f0aa377af03c6ffed7b","ef5424cbc14040e8aca98abf56ce7f05","a87a66a2e9a6469fa69d8b0e524944bb","50dce87064b74b9cbbb0e3738b5af021","cc7a41af1370480bab9f583470aa33c8","ea79fe403d7c47e386b52c22cf6b787d","93a8a64031c54fe983c69b3baad313e9","2c2780335e54467fad18076a79897e40"]},"id":"8PwD3Cd-9dzo","executionInfo":{"status":"error","timestamp":1750921054687,"user_tz":300,"elapsed":835936,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}},"outputId":"c5389589-6629-4b70-a570-32b98e8a3e9b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b636b1b2d44d4c19acf15e81e4bb845a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1800' max='1800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1800/1800 13:48, Epoch 6/6]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy Age</th>\n","      <th>F1 Age</th>\n","      <th>Accuracy Gender</th>\n","      <th>F1 Gender</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.666700</td>\n","      <td>1.689277</td>\n","      <td>0.425000</td>\n","      <td>0.348831</td>\n","      <td>0.621667</td>\n","      <td>0.621287</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.355300</td>\n","      <td>1.712081</td>\n","      <td>0.485000</td>\n","      <td>0.480164</td>\n","      <td>0.642500</td>\n","      <td>0.641747</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.843900</td>\n","      <td>2.040062</td>\n","      <td>0.476667</td>\n","      <td>0.463638</td>\n","      <td>0.627500</td>\n","      <td>0.626535</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.237500</td>\n","      <td>2.796715</td>\n","      <td>0.472500</td>\n","      <td>0.472489</td>\n","      <td>0.618333</td>\n","      <td>0.618265</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.077800</td>\n","      <td>3.412782</td>\n","      <td>0.466667</td>\n","      <td>0.464970</td>\n","      <td>0.611667</td>\n","      <td>0.611190</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.024800</td>\n","      <td>3.704114</td>\n","      <td>0.455833</td>\n","      <td>0.455596</td>\n","      <td>0.619167</td>\n","      <td>0.618974</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"'RobertaMultitaskClassifier' object has no attribute 'save_pretrained'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[22], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# ========== PARTE 6: Guardar en formato safetensors ==========\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./modelo_publico\u001b[39m\u001b[38;5;124m\"\u001b[39m, safe_serialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    128\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./modelo_publico\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32m~\\.conda\\envs\\colab-gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n","\u001b[1;31mAttributeError\u001b[0m: 'RobertaMultitaskClassifier' object has no attribute 'save_pretrained'"]}]},{"cell_type":"code","source":["# Guardar modelo y tokenizer\n","output_dir = \"modelo_publico\"\n","\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","print(f\"Modelo y tokenizer guardados en {output_dir}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjY_OzrBB1Ub","executionInfo":{"status":"ok","timestamp":1750921339956,"user_tz":300,"elapsed":1676,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}},"outputId":"7f9df7ec-13a4-4f85-f500-5cb87152d7c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Modelo y tokenizer guardados en modelo_publico\n"]}]},{"cell_type":"code","source":["import torch\n","from safetensors.torch import load_file\n","from transformers import AutoTokenizer\n","\n","# Cargar tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"modelo_publico\")\n","\n","# Reconstruir modelo multitarea\n","model = RobertaMultitaskClassifier(\n","    model_name=\"PlanTL-GOB-ES/roberta-base-bne\",\n","    num_labels_age=3,\n","    num_labels_gender=2\n",")\n","\n","# Cargar pesos desde archivo .safetensors\n","state_dict = load_file(\"modelo_publico/model.safetensors\", device=\"cuda\")  # o \"cpu\"\n","model.load_state_dict(state_dict)\n","model.to(\"cuda\")  # si estás usando GPU\n","model.eval()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pbmUkhfzAsFD","executionInfo":{"status":"ok","timestamp":1751248244061,"user_tz":300,"elapsed":5988,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}},"outputId":"e260a8f6-860d-46cd-ac2d-d68dba83d771"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of RobertaModel were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["RobertaMultitaskClassifier(\n","  (encoder): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50262, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSdpaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.0, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier_age): Linear(in_features=768, out_features=3, bias=True)\n","  (classifier_gender): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Evaluación final\n","from transformers import Trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer\n","    # Puedes agregar args, dataset, etc.\n",")\n","predictions = trainer.predict(test_dataset)\n","preds = np.argmax(predictions.predictions, axis=-1)\n","print(classification_report(test_df['labels'], preds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"EtiX3249huJN","executionInfo":{"status":"error","timestamp":1751248357248,"user_tz":300,"elapsed":534,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}},"outputId":"b8ccfc99-b17c-4044-fc4b-04c2edd1fe76"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\Iverno\\AppData\\Local\\Temp\\ipykernel_11788\\433501842.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'test_dataset' is not defined","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      6\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Puedes agregar args, dataset, etc.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtest_dataset\u001b[49m)\n\u001b[0;32m     10\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions\u001b[38;5;241m.\u001b[39mpredictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], preds))\n","\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn.functional as F\n","\n","def predecir_batch(textos):\n","    model.eval()\n","    inputs = tokenizer(textos, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n","\n","    # Si estás usando GPU\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        probs_age = F.softmax(outputs[\"logits_age\"], dim=1)\n","        probs_gender = F.softmax(outputs[\"logits_gender\"], dim=1)\n","\n","        preds_age = torch.argmax(probs_age, dim=1).tolist()\n","        preds_gender = torch.argmax(probs_gender, dim=1).tolist()\n","\n","    resultados = []\n","    for i in range(len(textos)):\n","        resultados.append({\n","            \"texto\": textos[i],\n","            \"edad\": [\"18-29\", \"30-39\", \"40-49\"][preds_age[i]],\n","            \"probs_edad\": [round(p, 4) for p in probs_age[i].tolist()],\n","            \"genero\": [\"male\", \"female\"][preds_gender[i]],\n","            \"probs_genero\": [round(p, 4) for p in probs_gender[i].tolist()]\n","        })\n","\n","    return resultados"],"metadata":{"id":"GD-J_fDhA6HU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["textos = [\n","    \"No entiendo cómo usan TikTok, me siento viejo.\",\n","    \"Ey bro, qué onda ese juego nuevo que salió ayer?\",\n","    \"Prefiero leer el diario en papel, como antes.\"\n","]\n","\n","resultados = predecir_batch(textos)\n","\n","for r in resultados:\n","    print(f\"Texto: {r['texto']}\")\n","    print(f\"Edad predicha: {r['edad']}  -  Probabilidades: {r['probs_edad']}\")\n","    print(f\"Género predicho: {r['genero']}  -  Probabilidades: {r['probs_genero']}\")\n","    print(\"-\" * 60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F7GuJ87_BDW0","executionInfo":{"status":"ok","timestamp":1750922837488,"user_tz":300,"elapsed":203,"user":{"displayName":"Marco Mendoza Quelal","userId":"04164926989622038255"}},"outputId":"7a3a8358-bb4d-4295-dcbf-049e01726d1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto: No entiendo cómo usan TikTok, me siento viejo.\n","Edad predicha: 18-29  -  Probabilidades: [0.555, 0.3704, 0.0746]\n","Género predicho: male  -  Probabilidades: [0.7323, 0.2677]\n","------------------------------------------------------------\n","Texto: Ey bro, qué onda ese juego nuevo que salió ayer?\n","Edad predicha: 18-29  -  Probabilidades: [0.7734, 0.1396, 0.087]\n","Género predicho: female  -  Probabilidades: [0.4795, 0.5205]\n","------------------------------------------------------------\n","Texto: Prefiero leer el diario en papel, como antes.\n","Edad predicha: 18-29  -  Probabilidades: [0.464, 0.4135, 0.1225]\n","Género predicho: male  -  Probabilidades: [0.728, 0.272]\n","------------------------------------------------------------\n"]}]}]}